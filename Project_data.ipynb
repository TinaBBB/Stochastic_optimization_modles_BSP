{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Project_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz0WTqpWh-op"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import pickle\n",
        "import json\n",
        "from numpy.random import rand, randint, exponential, normal, uniform, lognormal, dirichlet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFn6jUIA1HDx"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH9hLmY9kOFs",
        "outputId": "8fe83a30-f560-4682-d2d9-cf2bcd293dfd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64nGG-vUlFli"
      },
      "source": [
        "project_dir = '/content/drive/MyDrive/MASc_First_Year/MIE1612/Project'\n",
        "data_dir = project_dir+ '/data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Los5TEVrdYU7"
      },
      "source": [
        "# functions for dumping and loading generated data files\n",
        "def pickle_dump(file_to_dump, file_dir):\n",
        "  with open(file_dir, \"wb\") as fp:   #Pickling\n",
        "    pickle.dump(file_to_dump, fp)\n",
        "\n",
        "def pickle_load(file_dir):\n",
        "  with open(file_dir, \"rb\") as fp:   # Unpickling\n",
        "    return pickle.load(fp)\n",
        "\n",
        "def json_dump(file_to_dump, file_dir):\n",
        "    with open(file_dir, 'w') as fp:\n",
        "        json.dump(file_to_dump, fp)\n",
        "\n",
        "def json_load(file_dir):\n",
        "    with open(file_dir) as f:\n",
        "        return json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUAeUsg9h-op"
      },
      "source": [
        "### <b>1.Sets initialization</b>\n",
        "\n",
        "B: set of bike-stations, B = {1, ..., B} <br>\n",
        "S: set of scenarios, S = {1,...,S} or finit set of possible realization of the uncertainty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUjoH6Q0h-op"
      },
      "source": [
        "# Sets\n",
        "Bset = 'A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V'.split(',')  # 22 Bike Stations\n",
        "Bij_set = [(bike2, bike) for bike2 in Bset for bike in Bset]     # Bike pairs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG1SfbKYdXZC"
      },
      "source": [
        "# dump sets\n",
        "pickle_dump(Bset, data_dir + 'Bset.txt')\n",
        "pickle_dump(Bij_set, data_dir + 'Bij_set.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzyvAlc8h-op"
      },
      "source": [
        "#### <b>2.Deterministic parameters</b>\n",
        "\n",
        "c: procurement cost per bike at each bike-station at the beginning of the service <br>\n",
        "$v_i$: stock-out cost per bike at bike-station i $\\in$ B <br>\n",
        "$w_i$: time-waste cost per bike due to overflow at bike-station i $\\in$ B <br>\n",
        "$t_{ij}$: unit transshipment cost per bike transshiped from bike-station i to bike-station j, i,j $\n",
        "\\in$ B <br>\n",
        "$k_i$: capacity of bike-station i $\\in$ B <br>\n",
        "$\\xi_{ijk}$: rental demand from bike-station i to bike-station j in scenario s, i, j $\\in$ B, s $\\in$ S  <br>\n",
        "$p_s \\in [0,1]$: probability of scenario s $\\in$ S, $\\sum_{s=1}^{S} p_s$ = 1<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_GqwC7unoT6"
      },
      "source": [
        "c = 2         # unit procurement cost\n",
        "v_i = 4       # stock-out cost\n",
        "w_i = 8       # time-waste cost \n",
        "t_ij = 1      # unit transshipment cost \n",
        "deterministic_params = {'c': c, 'v_i': v_i, 'w_i': w_i, 't_ij': t_ij}\n",
        "\n",
        "# capacity for each station \n",
        "k_i = [22, 10, 10, 17, 19, 12, 20, 8, 8, 20, 10, 19, 8, 10, 10, 10, 18, 10, 8, 12, 12, 10]\n",
        "capacity_i = {Bset[index] : k_i[index] for index in range(len(Bset))}\n",
        "capacity_i_constant = {station: 50 for station in Bset}   # for the constant capacity case (not using for now)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-wAzu3DnrUA"
      },
      "source": [
        "# dump data\n",
        "json_dump(deterministic_params, data_dir + 'deterministic_params.json')\n",
        "json_dump(capacity_i, data_dir + 'capacity_i.json')\n",
        "json_dump(capacity_i_constant, data_dir + 'capacity_i_constant.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VADwoEHPntCb"
      },
      "source": [
        "#### <b>3. Stochastic generation</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd9WH531yWZQ"
      },
      "source": [
        "# demand generation function \n",
        "def generate_demand(distributions, Sset, Bij_set, mean_ij, sigma_ij):\n",
        "  demScens = {}\n",
        "\n",
        "  # Generate demand using log-normal distribution \n",
        "  # stochastic demand stored in form {((B_i, B_j), S_s) : demand}\n",
        "  for distribution_choice, dist in distributions.items():\n",
        "    print('--------------------%s--------------------'%distribution_choice)\n",
        "    for sta_idx in tqdm(range(len(Bij_set))):\n",
        "      station_pair = Bij_set[sta_idx]\n",
        "      for scenario in Sset:\n",
        "        # diagonal demands set to 0 \n",
        "        if station_pair[0] == station_pair[1]:\n",
        "          demand = 0\n",
        "        elif distribution_choice == 'log-normal':\n",
        "          demand = apply_upper_bound(int(dist(mean_ij[station_pair], sigma_ij[station_pair])))\n",
        "        elif distribution_choice == 'normal':\n",
        "          demand = apply_upper_bound(abs(int(dist(mean_ij[station_pair], sigma_ij[station_pair]))))\n",
        "        elif distribution_choice == 'exponential':\n",
        "          demand = apply_upper_bound(int(dist(mean_ij[station_pair])))\n",
        "        elif distribution_choice == 'uniform':\n",
        "          demand = apply_upper_bound(mean_ij[station_pair])\n",
        "        else:\n",
        "          assert(False)\n",
        "          print('Invalid distribution!!!')\n",
        "\n",
        "        demScens[(station_pair[0], station_pair[1], scenario)] = demand\n",
        "    pickle_dump(demScens, data_dir + 'demScens_' + distribution_choice + '_' + str(len(Sset)) + '.dict')\n",
        "\n",
        "def apply_upper_bound(number):\n",
        "  return min(number, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIoqSwYEyHYO"
      },
      "source": [
        "Run only once to generate consistent probabilities and distribution parameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtv2yzNhlN74"
      },
      "source": [
        "## Parameters\n",
        "# mean_ij = {station_pair: randint(math.log(4), math.log(10)) for station_pair in Bij_set}\n",
        "mean_ij = {station_pair: randint(1, 2) for station_pair in Bij_set}\n",
        "sigma_ij = {station_pair: rand()/5 for station_pair in Bij_set}\n",
        "\n",
        "## Distributions\n",
        "distributions = {'log-normal': lognormal, 'normal': normal, 'uniform': uniform, 'exponential': exponential}\n",
        "\n",
        "# Stochastic demand\n",
        "np.random.seed(1612)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eyu_ozMch-op"
      },
      "source": [
        "scenario_num_set = [100,300,500,700,900,1000]  # scenario number set\n",
        "for scenario_num in scenario_num_set:\n",
        "  print('Generating for %d number of scenarios' % scenario_num)                                       \n",
        "  Sset = ['S'+str(s) for s in range(scenario_num)]                 # Scenario sets\n",
        "  prob = np.around(np.random.dirichlet(np.ones(len(Sset))), decimals = 7)      # not consistent?\n",
        "  p_s = {scenario: prob[int(''.join(list(scenario)[1:]))]  for scenario in Sset}\n",
        "\n",
        "  generate_demand(distributions, Sset, Bij_set, mean_ij, sigma_ij)\n",
        "\n",
        "  # dump data iteratively, each for one scenario number \n",
        "  pickle_dump(Sset, data_dir+'Sset_' + str(scenario_num) + '.txt')\n",
        "  json_dump(p_s, data_dir + 'p_s_' + str(len(p_s)) + '.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRFJgdA91fWb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}